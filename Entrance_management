##this is for entrance management  environment is RaspberryPi5, python3.11

import cv2
import warnings
import torch
import numpy as np
import time
from collections import Counter
from PIL import Image, ImageDraw, ImageFont
import easyocr
import sys
from gpiozero import DigitalOutputDevice, DigitalInputDevice

YOLO_MODEL_PATH = "best_yolov5.pt"
REGISTERED_PLATES = ["01ê°€0785", "12ë‚˜3456", "66ë¡œ 3848", "57ì„œ 9757"]
MIN_TEXT_LENGTH = 8

GPIO_OUT_PIN = 17
GPIO_IN_PIN = 27

out_pin = DigitalOutputDevice(GPIO_OUT_PIN, initial_value = False)
in_pin = DigitalInputDevice(GPIO_IN_PIN)

out_pin.off()

warnings.filterwarnings("ignore", category=FutureWarning)

cv2.namedWindow("YOLO + EasyOCR", cv2.WINDOW_NORMAL)
cv2.resizeWindow("YOLO + EasyOCR", 800, 600)
cv2.namedWindow("ë“±ë¡ ì—¬ë¶€ ì•ˆë‚´", cv2.WINDOW_NORMAL)
cv2.resizeWindow("ë“±ë¡ ì—¬ë¶€ ì•ˆë‚´", 800, 200)

font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
try:
    font = ImageFont.truetype(font_path, 40)
except:
    font = ImageFont.load_default()

def get_most_frequent_text(text_list, min_length):
    filtered = [t for t in text_list if len(t) >= min_length]
    if not filtered:
        return "?"
    return Counter(filtered).most_common(1)[0][0]

def draw_text_pil(image, text, font, position, color=(0, 255, 0)):
    img_pil = Image.fromarray(image)
    draw = ImageDraw.Draw(img_pil)
    draw.text(position, text, font=font, fill=color)
    return np.array(img_pil)

def send_pulse():
    out_pin.on()
    time.sleep(2)
    out_pin.off()

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # YOLO ëª¨ë¸ ë¡œë“œ (device ì§€ì • ì—†ì´ ë¡œë“œ, ë‚´ë¶€ì ìœ¼ë¡œ ì²˜ë¦¬ë¨)
    yolo = torch.hub.load('ultralytics/yolov5', 'custom', path=YOLO_MODEL_PATH)
    yolo.eval()

    reader = easyocr.Reader(['ko'])

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        sys.exit(1)

    state = "IDLE"
    detection_time = 0
    ocr_results = []
    final_text = ""
    result_msg = "ë²ˆí˜¸íŒì„ ì¸ì‹ ëŒ€ê¸°ì¤‘ì…ë‹ˆë‹¤..."
    cropped_plate = None

    ocr_start_time = 0
    ocr_count = 0

    print("Press 'q' to quit")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            if state == "IDLE":
                results = yolo(rgb, size=160)
                dets = results.xyxy[0].cpu().numpy()
                for x1, y1, x2, y2, conf, cls in dets:
                    if int(cls) == 0 and conf > 0.5:
                        x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))
                        cropped_plate = frame[y1:y2, x1:x2]
                        detection_time = time.time()
                        ocr_results = []
                        final_text = ""
                        result_msg = "ë²ˆí˜¸íŒì„ ì¸ì‹ ì¤‘ì…ë‹ˆë‹¤..."
                        state = "WAIT_OCR"
                        print("ğŸ“· ë²ˆí˜¸íŒ ì¸ì‹ë¨ â†’ 5ì´ˆ ëŒ€ê¸° ì‹œì‘")
                        break

            elif state == "WAIT_OCR":
                if time.time() - detection_time >= 5:
                    print("ğŸ” OCR ì‹œì‘")
                    state = "RUN_OCR"
                    ocr_start_time = time.time()
                    ocr_count = 0

            elif state == "RUN_OCR":
                current_time = time.time()
                if ocr_count < 10 and current_time - ocr_start_time >= 0.5:
                    ocr_start_time = current_time
                    # ë‹¤ì‹œ ë²ˆí˜¸íŒ ê²€ì¶œí•´ì„œ ìœ„ì¹˜ í™•ì¸ (optional, ìƒëµ ê°€ëŠ¥)
                    results = yolo(rgb, size=160)
                    dets = results.xyxy[0].cpu().numpy()
                    detected = False
                    for x1, y1, x2, y2, conf, cls in dets:
                        if int(cls) == 0 and conf > 0.5:
                            x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))
                            cropped_plate = frame[y1:y2, x1:x2]
                            text_result = reader.readtext(cropped_plate, detail=0)
                            text = text_result[0] if text_result else "?"
                            ocr_results.append(text)
                            print(f"OCR ê²°ê³¼ {ocr_count + 1}/10: {text}")
                            ocr_box = (x1, y1, x2, y2)
                            ocr_text = text
                            ocr_count += 1
                            detected = True
                            break
                    if not detected:
                        print("ë²ˆí˜¸íŒ ê²€ì¶œ ì‹¤íŒ¨, OCR ìƒëµ")
                elif ocr_count >= 10:
                    final_text = get_most_frequent_text(ocr_results, MIN_TEXT_LENGTH)
                    print(f"âœ… ìµœì¢… ì¸ì‹ ë¬¸ìì—´: {final_text}")
                    if final_text in REGISTERED_PLATES:
                        send_pulse()
                        time.sleep(0.1)
                        if in_pin.is_active:
                            result_msg = f"{final_text} - ë“±ë¡ ì°¨ëŸ‰ì´ì§€ë§Œ ë§Œì°¨ì…ë‹ˆë‹¤."
                        else:
                            result_msg = f"{final_text} - ë“±ë¡ëœ ì°¨ëŸ‰ì…ë‹ˆë‹¤."
                    else:
                        result_msg = f"{final_text} - ë¯¸ë“±ë¡ ì°¨ëŸ‰ì…ë‹ˆë‹¤."
                    print("ğŸ“¢", result_msg)
                    state = "DONE_WAIT"
                    done_time = time.time()

            elif state == "DONE_WAIT":
                if time.time() - done_time >= 5:
                    state = "IDLE"
                    result_msg = "ë²ˆí˜¸íŒì„ ì¸ì‹ ëŒ€ê¸°ì¤‘ì…ë‹ˆë‹¤..."
                    final_text = ""
                    print("ğŸ” ë‹¤ìŒ ì°¨ëŸ‰ ëŒ€ê¸° ì¤‘ (IDLE ìƒíƒœë¡œ ì „í™˜)")

            # ì˜ìƒ ì¶œë ¥
            pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(pil_img)
            if state in ["WAIT_OCR", "RUN_OCR", "DONE_WAIT"]:
                draw.text((50, 50), final_text if final_text else "ì¸ì‹ ì¤‘...", font=font, fill=(0, 255, 0))
            if state == "RUN_OCR" and 'ocr_box' in locals() and 'ocr_text' in locals():
                x1, y1, x2, y2 = ocr_box
                draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0), width=3)
                draw.text((x1, y1 - 30), ocr_text, font=font, fill=(255, 0, 0))
            frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            cv2.imshow("YOLO + EasyOCR", frame)

            # ë“±ë¡ ì—¬ë¶€ ì•ˆë‚´ì°½
            if state == "IDLE":
                bg_color = (0, 0, 0)
                text_color = (255, 0, 0)
            elif "ë§Œì°¨" in result_msg:
                bg_color = (0, 255, 255)
                text_color = (0, 0, 0)
            elif "ë“±ë¡ëœ" in result_msg:
                bg_color = (0, 255, 0)
                text_color = (0, 0, 0)
            elif "ë¯¸ë“±ë¡" in result_msg:
                bg_color = (0, 0, 255)
                text_color = (0, 0, 0)
            else:
                bg_color = (0, 0, 0)
                text_color = (255, 255, 255)

            result_image = np.full((200, 800, 3), bg_color, dtype=np.uint8)
            result_image = draw_text_pil(result_image, result_msg, font, (30, 70), color=text_color)
            cv2.imshow("ë“±ë¡ ì—¬ë¶€ ì•ˆë‚´", result_image)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except KeyboardInterrupt:
        print("\nì¢…ë£Œ ì¤‘...")

    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

if __name__ == "__main__":
    main()
